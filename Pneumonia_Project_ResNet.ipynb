{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25782,"status":"ok","timestamp":1755718409889,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"},"user_tz":-330},"id":"PDY4Tid714Nq","outputId":"65041d8b-358a-43ca-f9fc-d48136d20839"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2225,"status":"ok","timestamp":1755718412103,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"},"user_tz":-330},"id":"_zbBuHhMWL5n","outputId":"9130f138-9e01-47cb-f459-7de7985e97c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}],"source":["\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from torch.optim import Adam\n","import matplotlib.pyplot as plt\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19003,"status":"ok","timestamp":1755718437909,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"},"user_tz":-330},"id":"j0qObANO9G1_","outputId":"35b1e3c7-6e53-4b05-ab0c-7c6b865ed425"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 5216, Val samples: 16, Test samples: 624\n"]}],"source":["base_dir = '/content/drive/MyDrive/chest_xray/chest_xray'\n","train_dir = base_dir + '/train'\n","validation_dir = base_dir + '/val'\n","test_dir = base_dir + '/test'\n","\n","# ImageNet normalization stats\n","imagenet_mean = [0.485, 0.456, 0.406]\n","imagenet_std = [0.229, 0.224, 0.225]\n","\n","train_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomRotation(degrees=15),\n","    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),  # small shifts\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","val_test_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","\n","train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n","val_dataset = datasets.ImageFolder(root=validation_dir, transform=val_test_transforms)\n","test_dataset = datasets.ImageFolder(root=test_dir, transform=val_test_transforms)\n","\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1755718464312,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"},"user_tz":-330},"id":"pHA5Y95e0nva","outputId":"b7d73700-7c1c-40b6-d28f-4c8f4cef98b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Class counts: Counter({1: 3875, 0: 1341})\n","Class weights: tensor([1.9448, 0.6730])\n"]}],"source":["from collections import Counter\n","import torch\n","\n","def get_targets_from_dataset(ds):\n","    # Handle Subset(ImageFolder(...)) or plain ImageFolder\n","    if hasattr(ds, 'dataset') and hasattr(ds, 'indices'):\n","        base = ds.dataset\n","        idxs = ds.indices\n","        if hasattr(base, 'targets'):\n","            return [base.targets[i] for i in idxs]\n","        elif hasattr(base, 'samples'):\n","            return [base.samples[i][1] for i in idxs]\n","    else:\n","        if hasattr(ds, 'targets'):\n","            return list(ds.targets)\n","        elif hasattr(ds, 'samples'):\n","            return [s[1] for s in ds.samples]\n","    # Fallback (slow)\n","    return [label for _, label in ds]\n","\n","targets = get_targets_from_dataset(train_loader.dataset)\n","class_counts = Counter(targets)\n","num_classes = len(class_counts)\n","\n","# Inverse-frequency class weights (higher = rarer class)\n","class_weights = torch.zeros(num_classes, dtype=torch.float)\n","total = len(targets)\n","for cls, cnt in class_counts.items():\n","    class_weights[cls] = total / (num_classes * cnt)\n","\n","class_weights = class_weights.to(device)\n","print(\"Class counts:\", class_counts)\n","print(\"Class weights:\", class_weights)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1755718465670,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"},"user_tz":-330},"id":"2816-4ehTOjU","outputId":"e0d83b82-0706-41e7-dfac-38f0a90a66da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Rebuilt train_loader with WeightedRandomSampler.\n"]}],"source":["import numpy as np\n","from torch.utils.data import WeightedRandomSampler, DataLoader\n","\n","# Per-sample weights: pick class weight for each sample’s label\n","sample_weights = np.array([class_weights[label].item() for label in targets], dtype=np.float64)\n","\n","sampler = WeightedRandomSampler(\n","    weights=sample_weights,\n","    num_samples=len(sample_weights),\n","    replacement=True\n",")\n","\n","# Rebuild train_loader with the sampler (do NOT use shuffle with sampler)\n","train_loader = DataLoader(\n","    train_loader.dataset,\n","    batch_size=train_loader.batch_size if hasattr(train_loader, \"batch_size\") else 32,\n","    sampler=sampler,\n","    num_workers=train_loader.num_workers if hasattr(train_loader, \"num_workers\") else 2,\n","    pin_memory=True\n",")\n","print(\"Rebuilt train_loader with WeightedRandomSampler.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":449,"status":"ok","timestamp":1755718468125,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"},"user_tz":-330},"id":"7vrltcTcFTXD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a5279f2-6121-4842-9323-894f394b3005"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 44.7M/44.7M [00:00<00:00, 323MB/s]\n"]}],"source":["model=models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","for param in model.parameters():\n","  param.requires_grad= False\n","num_features = model.fc.in_features  # number of inputs to the FC layer\n","model.fc = nn.Linear(num_features, 2)  # new FC layer for 2 output classes\n","\n","model=model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mRLfhtEQObp","outputId":"b3dfa68a-2b0a-4d43-87f5-9d17dfbf0682","executionInfo":{"status":"ok","timestamp":1755544134503,"user_tz":-330,"elapsed":4877990,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30 | Train Loss: 0.1207 | Val Loss: 0.1009 | Val Acc: 93.75% | Macro Recall: 0.938\n","Epoch 2/30 | Train Loss: 0.0753 | Val Loss: 0.1634 | Val Acc: 93.75% | Macro Recall: 0.938\n","Epoch 3/30 | Train Loss: 0.0666 | Val Loss: 0.0703 | Val Acc: 87.50% | Macro Recall: 0.875\n","Epoch 4/30 | Train Loss: 0.0653 | Val Loss: 0.1601 | Val Acc: 93.75% | Macro Recall: 0.938\n","Epoch 5/30 | Train Loss: 0.0670 | Val Loss: 0.1420 | Val Acc: 93.75% | Macro Recall: 0.938\n","Epoch 6/30 | Train Loss: 0.0564 | Val Loss: 0.1041 | Val Acc: 100.00% | Macro Recall: 1.000\n","Epoch 7/30 | Train Loss: 0.0609 | Val Loss: 0.0833 | Val Acc: 93.75% | Macro Recall: 0.938\n","Epoch 8/30 | Train Loss: 0.0587 | Val Loss: 0.0553 | Val Acc: 93.75% | Macro Recall: 0.938\n","Epoch 9/30 | Train Loss: 0.0597 | Val Loss: 0.1482 | Val Acc: 87.50% | Macro Recall: 0.875\n","Epoch 10/30 | Train Loss: 0.0539 | Val Loss: 0.0764 | Val Acc: 100.00% | Macro Recall: 1.000\n","Epoch 11/30 | Train Loss: 0.0569 | Val Loss: 0.0489 | Val Acc: 87.50% | Macro Recall: 0.875\n","Early stopping triggered.\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import recall_score\n","\n","drive_path = '/content/drive/MyDrive/chest_xray/best_model.pth'\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.reduction = reduction\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = nn.functional.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n","        if self.reduction == 'mean':\n","            return focal_loss.mean()\n","        elif self.reduction == 'sum':\n","            return focal_loss.sum()\n","        else:\n","            return focal_loss\n","\n","criterion = FocalLoss(alpha=class_weights.to(device))\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","num_epochs = 30\n","patience = 5\n","best_val_recall = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss, correct, total = 0, 0, 0\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","    train_acc = 100. * correct / total\n","\n","    model.eval()\n","    val_loss, correct, total = 0, 0, 0\n","    all_targets, all_preds = [], []\n","    with torch.no_grad():\n","        for inputs, targets in val_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            val_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","            all_targets.extend(targets.cpu().numpy())\n","            all_preds.extend(predicted.cpu().numpy())\n","    val_acc = 100. * correct / total\n","    val_recall = recall_score(all_targets, all_preds, average='macro')\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss/len(train_loader):.4f} | \"\n","          f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.2f}% | Macro Recall: {val_recall:.3f}\")\n","\n","    if val_recall > best_val_recall:\n","        best_val_recall = val_recall\n","        torch.save({\n","            'epoch': epoch+1,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'val_macro_recall': val_recall\n","        }, drive_path)\n","        epochs_no_improve = 0\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print(\"Early stopping triggered.\")\n","            break\n"]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","drive_path = \"/content/drive/MyDrive/chest_xray/best_model.pth\"\n","\n","checkpoint = torch.load(drive_path, map_location=device)\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","epoch = checkpoint[\"epoch\"]\n","best_val_recall = checkpoint[\"val_macro_recall\"]\n","\n","print(f\"Model restored from epoch {epoch}, achieving a validation macro recall of {best_val_recall:.3f}\")\n","model.eval()\n"],"metadata":{"id":"v4ofc6LSxM0B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755718479181,"user_tz":-330,"elapsed":3609,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"}},"outputId":"72ec190c-863a-40bd-f819-a54712dd990b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model restored from epoch 6, achieving a validation macro recall of 1.000\n"]},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6suBtuYy8uOO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755718810270,"user_tz":-330,"elapsed":327647,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"}},"outputId":"dbb02df4-d64f-44d6-9c01-2e3e11d21928"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","      NORMAL       0.83      0.90      0.86       234\n","   PNEUMONIA       0.94      0.89      0.91       390\n","\n","    accuracy                           0.89       624\n","   macro avg       0.88      0.89      0.89       624\n","weighted avg       0.90      0.89      0.89       624\n","\n","Confusion Matrix:\n","[[211  23]\n"," [ 44 346]]\n"]}],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","\n","model.eval()\n","all_labels = []\n","all_preds = []\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        all_labels.extend(labels.cpu().numpy())\n","        all_preds.extend(predicted.cpu().numpy())\n","\n","\n","print(classification_report(all_labels, all_preds, target_names=['NORMAL', 'PNEUMONIA']))\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(all_labels, all_preds))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BWGSpBN9-_Wm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755718859152,"user_tz":-330,"elapsed":48892,"user":{"displayName":"Vipul Parmar","userId":"08446776238704462438"}},"outputId":"39293c84-840a-4f95-f796-22bdd41dde96"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best checkpoint: epoch 6, val macro recall 1.000\n","Test Acc: 89.26% | Test Macro Recall: 0.894\n","              precision    recall  f1-score   support\n","\n","      NORMAL       0.83      0.90      0.86       234\n","   PNEUMONIA       0.94      0.89      0.91       390\n","\n","    accuracy                           0.89       624\n","   macro avg       0.88      0.89      0.89       624\n","weighted avg       0.90      0.89      0.89       624\n","\n","Confusion Matrix:\n","[[211  23]\n"," [ 44 346]]\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torchvision import models\n","from sklearn.metrics import accuracy_score, recall_score, classification_report, confusion_matrix\n","\n","model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","for p in model.parameters():\n","    p.requires_grad = False\n","num_features = model.fc.in_features\n","model.fc = nn.Linear(num_features, 2)\n","model = model.to(device)\n","\n","checkpoint = torch.load(drive_path, map_location=device)\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","epoch = checkpoint[\"epoch\"]\n","best_val_recall = checkpoint[\"val_macro_recall\"]\n","print(f\"Best checkpoint: epoch {epoch}, val macro recall {best_val_recall:.3f}\")\n","\n","model.eval()\n","all_true, all_pred = [], []\n","with torch.no_grad():\n","    for x, y in test_loader:\n","        x, y = x.to(device), y.to(device)\n","        logits = model(x)\n","        preds = torch.argmax(logits, dim=1)\n","        all_true.extend(y.cpu().numpy())\n","        all_pred.extend(preds.cpu().numpy())\n","\n","acc = accuracy_score(all_true, all_pred)\n","macro_recall = recall_score(all_true, all_pred, average=\"macro\")\n","report = classification_report(all_true, all_pred, target_names=[\"NORMAL\",\"PNEUMONIA\"])\n","cm = confusion_matrix(all_true, all_pred, labels=[0,1])\n","\n","print(f\"Test Acc: {acc*100:.2f}% | Test Macro Recall: {macro_recall:.3f}\")\n","print(report)\n","print(\"Confusion Matrix:\")\n","print(cm)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"m5CH63a--5e3"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSfJrOkGvYFQMHxUfTmC+x"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}